# OmenDB vs pgvector Benchmark Results (100K Vectors)

**Date**: October 29, 2025
**Hardware**: Mac M3 Max, 16 cores, 128GB RAM
**Dataset**: 100,000 vectors Ã— 1536 dimensions (OpenAI embedding size)
**Parameters**: M=16, ef_construction=64 (pgvector defaults)

## Results

### OmenDB (Parallel Building)

| Metric | Value |
|--------|-------|
| Build time | 31.05s (3220 vec/sec) |
| Save time | 0.87s |
| Query avg | 5.04ms |
| Query p50 | 4.95ms |
| Query p95 | 6.16ms |
| Query p99 | 6.91ms |
| Disk usage | TBD |

### pgvector (Single-threaded Building)

| Metric | Value |
|--------|-------|
| Insert time | 37.95s (2635 vec/sec) |
| Index build time | 2988.32s (~50 minutes) |
| Total build time | 3026.27s (33 vec/sec) |
| Query avg | 11.70ms |
| Query p50 | 11.53ms |
| Query p95 | 13.60ms |
| Query p99 | 14.80ms |
| Disk usage | 1579 MB |

## Performance Comparison

| Dimension | OmenDB | pgvector | Advantage |
|-----------|--------|----------|-----------|
| **Build Speed** | 31.05s | 3026.27s | **97x faster** |
| **Query Latency (p95)** | 6.16ms | 13.60ms | **2.2x faster** |
| **Query Latency (avg)** | 5.04ms | 11.70ms | **2.3x faster** |

## Key Findings

1. **Massive Build Speed Advantage**: OmenDB's parallel HNSW building is **97x faster** than pgvector at 100K scale
   - OmenDB: 31 seconds
   - pgvector: 50 minutes
   - Both using identical parameters (M=16, ef_construction=64)

2. **Better Query Performance**: OmenDB is **2.2x faster** for queries
   - Lower latency across all percentiles (p50, p95, p99)
   - More consistent performance

3. **Real-World Parameters**: These results use pgvector's default parameters (M=16, ef_construction=64)
   - Not cherry-picked aggressive parameters
   - What actual users experience in production

## Configuration Details

**HNSW Parameters** (identical for both):
- M (max connections): 16
- ef_construction: 64
- ef_search: 100 (pgvector), default (OmenDB)

**Database Configuration**:
- PostgreSQL 17
- pgvector 0.8.1

**Test Methodology**:
- Same random seed for data generation
- Same hardware (Mac M3 Max)
- Fair comparison: identical HNSW parameters

## Implications

1. **Development Velocity**: 97x faster builds means rapid iteration
2. **Production Deployments**: Faster reindexing for updates
3. **Cost Efficiency**: Less compute time = lower costs
4. **User Experience**: 2.2x faster queries = better application responsiveness

## Next Steps

- [ ] Run 3 iterations, report median (for statistical validity)
- [ ] Test at 1M scale (where gap likely widens)
- [ ] Compare disk usage properly
- [ ] Test with Binary Quantization enabled
- [ ] Measure recall accuracy (should be identical with same HNSW params)

## Notes

- pgvector's slow index build is due to single-threaded HNSW construction
- OmenDB uses Rayon for parallel building across all available cores
- Query performance difference likely due to implementation optimizations
- Both systems provide approximate nearest neighbor search with HNSW
