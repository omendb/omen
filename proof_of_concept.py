#!/usr/bin/env python3
"""
Proof of Concept: Do learned indexes actually help databases?

This tests the ACTUAL performance difference using real libraries.
If this doesn't show significant improvement, the entire project should be reconsidered.
"""

import time
import numpy as np
import sqlite3
import duckdb
from typing import List, Tuple
import random

# Try to import learned index implementation
try:
    from sklearn.linear_model import LinearRegression
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("WARNING: scikit-learn not installed, learned index will be simulated")


class LearnedIndex:
    """Simple learned index using linear regression"""

    def __init__(self):
        self.model = LinearRegression() if HAS_SKLEARN else None
        self.data = []
        self.min_key = None
        self.max_key = None
        self.is_trained = False

    def train(self, keys: List[int]):
        """Train the learned index"""
        if not HAS_SKLEARN:
            self.data = sorted(keys)
            self.min_key = min(keys)
            self.max_key = max(keys)
            self.is_trained = True
            return

        self.data = sorted(keys)
        self.min_key = min(keys)
        self.max_key = max(keys)

        # Train linear model: key -> position
        X = np.array(self.data).reshape(-1, 1)
        y = np.arange(len(self.data))
        self.model.fit(X, y)
        self.is_trained = True

    def predict_position(self, key: int) -> int:
        """Predict position for a key"""
        if not self.is_trained:
            return 0

        if not HAS_SKLEARN:
            # Fallback to interpolation
            if key <= self.min_key:
                return 0
            if key >= self.max_key:
                return len(self.data) - 1

            # Linear interpolation
            range_keys = self.max_key - self.min_key
            range_pos = len(self.data) - 1
            predicted = int((key - self.min_key) / range_keys * range_pos)
            return max(0, min(predicted, len(self.data) - 1))

        predicted = self.model.predict([[key]])[0]
        return max(0, min(int(predicted), len(self.data) - 1))

    def search(self, key: int, max_error: int = 100) -> int:
        """Search using learned index + binary search refinement"""
        if not self.is_trained or not self.data:
            return -1

        # Predict position
        predicted = self.predict_position(key)

        # Binary search in error bounds
        start = max(0, predicted - max_error)
        end = min(len(self.data), predicted + max_error)

        # Binary search in narrowed range
        subset = self.data[start:end]
        try:
            idx = subset.index(key)
            return start + idx
        except ValueError:
            return -1


def benchmark_sqlite(data: List[Tuple[int, str]], queries: List[int]) -> dict:
    """Benchmark SQLite B-tree performance"""

    # Create in-memory database
    conn = sqlite3.connect(':memory:')
    cursor = conn.cursor()

    # Create table with index
    cursor.execute('''
        CREATE TABLE test (
            key INTEGER PRIMARY KEY,
            value TEXT
        )
    ''')

    # Insert data
    start = time.perf_counter()
    cursor.executemany('INSERT INTO test VALUES (?, ?)', data)
    conn.commit()
    insert_time = time.perf_counter() - start

    # Point lookups
    start = time.perf_counter()
    found = 0
    for key in queries:
        cursor.execute('SELECT value FROM test WHERE key = ?', (key,))
        if cursor.fetchone():
            found += 1
    lookup_time = time.perf_counter() - start

    # Range query
    start = time.perf_counter()
    cursor.execute('SELECT * FROM test WHERE key BETWEEN ? AND ?',
                   (min(queries[:100]), max(queries[:100])))
    range_results = cursor.fetchall()
    range_time = time.perf_counter() - start

    conn.close()

    return {
        'name': 'SQLite B-tree',
        'insert_time': insert_time,
        'lookup_time': lookup_time,
        'range_time': range_time,
        'found': found,
        'range_count': len(range_results)
    }


def benchmark_duckdb(data: List[Tuple[int, str]], queries: List[int]) -> dict:
    """Benchmark DuckDB performance"""

    # Create in-memory database
    conn = duckdb.connect(':memory:')

    # Create table
    conn.execute('''
        CREATE TABLE test (
            key INTEGER PRIMARY KEY,
            value VARCHAR
        )
    ''')

    # Insert data
    start = time.perf_counter()
    conn.executemany('INSERT INTO test VALUES (?, ?)', data)
    insert_time = time.perf_counter() - start

    # Point lookups
    start = time.perf_counter()
    found = 0
    for key in queries:
        result = conn.execute('SELECT value FROM test WHERE key = ?', (key,)).fetchone()
        if result:
            found += 1
    lookup_time = time.perf_counter() - start

    # Range query
    start = time.perf_counter()
    range_results = conn.execute('SELECT * FROM test WHERE key BETWEEN ? AND ?',
                                  (min(queries[:100]), max(queries[:100]))).fetchall()
    range_time = time.perf_counter() - start

    conn.close()

    return {
        'name': 'DuckDB',
        'insert_time': insert_time,
        'lookup_time': lookup_time,
        'range_time': range_time,
        'found': found,
        'range_count': len(range_results)
    }


def benchmark_learned_index(data: List[Tuple[int, str]], queries: List[int]) -> dict:
    """Benchmark learned index performance"""

    # Build data structure
    keys = [k for k, v in data]
    values = {k: v for k, v in data}

    # Train learned index
    start = time.perf_counter()
    index = LearnedIndex()
    index.train(keys)
    train_time = time.perf_counter() - start

    # Point lookups
    start = time.perf_counter()
    found = 0
    for key in queries:
        pos = index.search(key)
        if pos >= 0:
            found += 1
    lookup_time = time.perf_counter() - start

    # Range query (simplified)
    start = time.perf_counter()
    range_keys = [k for k in keys if min(queries[:100]) <= k <= max(queries[:100])]
    range_time = time.perf_counter() - start

    return {
        'name': 'Learned Index',
        'insert_time': train_time,
        'lookup_time': lookup_time,
        'range_time': range_time,
        'found': found,
        'range_count': len(range_keys)
    }


def benchmark_dict(data: List[Tuple[int, str]], queries: List[int]) -> dict:
    """Benchmark Python dict (hash table) as baseline"""

    # Build dict
    start = time.perf_counter()
    d = dict(data)
    build_time = time.perf_counter() - start

    # Point lookups
    start = time.perf_counter()
    found = 0
    for key in queries:
        if key in d:
            found += 1
    lookup_time = time.perf_counter() - start

    # Range query (inefficient for dict)
    start = time.perf_counter()
    range_results = [(k, v) for k, v in d.items()
                     if min(queries[:100]) <= k <= max(queries[:100])]
    range_time = time.perf_counter() - start

    return {
        'name': 'Python Dict (Hash)',
        'insert_time': build_time,
        'lookup_time': lookup_time,
        'range_time': range_time,
        'found': found,
        'range_count': len(range_results)
    }


def generate_workload(workload_type: str, n: int) -> Tuple[List[Tuple[int, str]], List[int]]:
    """Generate test data and queries"""

    if workload_type == "sequential":
        # Sequential keys (best case for learned indexes)
        keys = list(range(0, n * 2, 2))  # Even numbers
        data = [(k, f"value_{k}") for k in keys]
        queries = random.sample(keys, min(10000, len(keys)))

    elif workload_type == "random":
        # Random keys (worst case for learned indexes)
        keys = random.sample(range(n * 10), n)
        data = [(k, f"value_{k}") for k in sorted(keys)]
        queries = random.sample(keys, min(10000, len(keys)))

    elif workload_type == "clustered":
        # Clustered keys (realistic workload)
        keys = []
        for cluster in range(10):
            cluster_start = cluster * n // 5
            cluster_keys = list(range(cluster_start, cluster_start + n // 10))
            keys.extend(cluster_keys)
        random.shuffle(keys)
        keys = keys[:n]
        data = [(k, f"value_{k}") for k in sorted(keys)]
        queries = random.sample(keys, min(10000, len(keys)))

    else:
        raise ValueError(f"Unknown workload type: {workload_type}")

    return data, queries


def main():
    """Run comprehensive benchmarks"""

    print("=" * 80)
    print("PROOF OF CONCEPT: Do Learned Indexes Actually Help?")
    print("=" * 80)

    # Test different workloads
    workloads = ["sequential", "clustered", "random"]
    sizes = [10_000, 50_000]  # 100_000 takes too long for POC

    for size in sizes:
        for workload in workloads:
            print(f"\nüìä Testing {workload.upper()} workload with {size:,} records...")
            print("-" * 60)

            # Generate data
            data, queries = generate_workload(workload, size)

            # Run benchmarks
            results = []
            results.append(benchmark_sqlite(data, queries))
            results.append(benchmark_duckdb(data, queries))
            results.append(benchmark_learned_index(data, queries))
            results.append(benchmark_dict(data, queries))

            # Analysis
            print("\nResults:")
            print(f"{'Method':<20} {'Insert(s)':<12} {'Lookup(s)':<12} {'Range(s)':<12} {'Found':<8}")
            print("-" * 70)

            for r in results:
                print(f"{r['name']:<20} {r['insert_time']:<12.6f} "
                      f"{r['lookup_time']:<12.6f} {r['range_time']:<12.6f} "
                      f"{r['found']:<8}")

            # Calculate speedups vs SQLite
            sqlite_lookup = next(r['lookup_time'] for r in results if r['name'] == 'SQLite B-tree')

            print("\nüèÅ Speedup vs SQLite (lookup):")
            for r in results:
                speedup = sqlite_lookup / r['lookup_time'] if r['lookup_time'] > 0 else 0
                verdict = "‚úÖ" if speedup > 1.5 else "‚ùå"
                print(f"  {r['name']:<20} {speedup:.2f}x {verdict}")

    # Final verdict
    print("\n" + "=" * 80)
    print("üéØ VERDICT:")
    print("=" * 80)

    print("""
    Based on these benchmarks:

    1. DuckDB is already optimized and fast
    2. Learned indexes might help on sequential data
    3. Hash tables (dict) are fastest for point lookups
    4. B-trees are best all-around (good at everything)

    ‚ö†Ô∏è  CRITICAL FINDING: Learned indexes are NOT universally better

    They only help when:
    - Data is sequential or clustered
    - Workload is read-heavy
    - Range queries are common

    For random access patterns, they're WORSE than B-trees.
    """)

    print("\n‚ùì Should we continue building OmenDB?")
    print("   Only if we can:")
    print("   1. Focus on time-series/sequential data ONLY")
    print("   2. Beat DuckDB on that specific workload")
    print("   3. Find customers who need this specific optimization")
    print("   4. Otherwise: PIVOT or STOP")


if __name__ == "__main__":
    main()