# OmenDB: Executive Summary & Viable Business Paths

**Date:** October 2, 2025
**Status:** Strategic Planning Phase
**Purpose:** Consolidated summary of most viable business models and technical architectures

---

## Current State (Updated: October 2025)

**What we have:**
- PostgreSQL-compatible database with DataFusion SQL engine
- **ALEX learned index** with proven 14.7x speedup on writes at 10M scale
- **249 tests passing**, production-ready Rust codebase
- Complete ALEX migration (TableIndex + RedbStorage + DataFusion integration)
- Validated linear scaling to 10M+ keys (vs O(n) rebuild bottlenecks)

**Performance validated:**
- âœ… 14.7x faster writes than RMI at 10M scale (1.95s vs 28.6s)
- âœ… 9.85x faster reads than B-trees on time-series workloads
- âœ… Linear scaling: 10.6x time for 10x data (vs 113x for RMI)
- âœ… No rebuild spikes in production (gapped arrays + local splits)

**Honest assessment vs SQLite:**
- 2.18-3.98x average speedup (not 100x, but honest comparison)
- ALEX advantage grows with scale and write-heavy workloads
- Read latency: 5.51Î¼s at 10M (vs 40.5Î¼s for old RMI)

---

## Three Viable Business Paths

### Path 1: Algorithm-First Strategy âš¡

**Positioning:** "Fastest embedded database for time-series and AI workloads"

**System Design:**
```
Core Components:
â”œâ”€â”€ ALEX Learned Index - Adaptive gapped arrays for dynamic workloads
â”œâ”€â”€ Columnar Storage (Arrow/Parquet) - Fast analytics
â”œâ”€â”€ PostgreSQL Wire Protocol - Drop-in replacement
â””â”€â”€ pgvector Integration - Vector similarity search (planned)

Validated Performance (October 2025):
â”œâ”€â”€ Bulk inserts (10M): 14.7x faster than RMI, linear scaling
â”œâ”€â”€ Point queries: 5.51Î¼s at 10M scale (9.85x faster than B-trees)
â”œâ”€â”€ Write throughput: ~500K ops/sec (no rebuild bottlenecks)
â””â”€â”€ Memory: 1.5x overhead (50% gaps) vs 2x for RMI+sorted array
```

**Business Model:**
- **Free:** Core database (open source, Apache 2.0)
- **Pro:** $299/month - Cloud sync, replication, monitoring
- **Enterprise:** $5K-50K/month - Multi-region, SLA, support

**Target Market:**
- IoT/sensor data applications ($1.45B â†’ $4.42B time-series market)
- AI/RAG applications ($4B vector database market by 2028)
- Edge computing (offline-first, sync optionally)

**Revenue Potential:**
- Year 1: $100K-500K ARR (bootstrap or $1-3M seed funding)
- Year 3: $5M-20M ARR (Series A: $10-30M at $50-100M valuation)

**Requirements:**
- âœ… ALEX learned index validated (14.7x write speedup at 10M)
- âœ… Linear scaling proven (ready for 100M+ rows)
- âœ… 249/249 tests passing (production ready)
- âš ï¸ Prove 10-100x speedup on vector search (needs pgvector integration)
- âš ï¸ Add pgvector integration (4-6 weeks)
- âš ï¸ Run TPC-H, TPC-C benchmarks against CockroachDB/TiDB

**Funding Strategy:**
- Lead with technical moat: "100x faster for X"
- YC/Seed: $500K-3M based on algorithm advantage
- Series A: $10-30M after proving market traction

**Risk Level:** High technical risk, high reward potential

**Success Examples:**
- DuckDB: 100x faster â†’ $52.5M funding, 15K stars
- ClickHouse: 1000x faster â†’ $250M funding, 30K stars
- QuestDB: 10x faster â†’ $15M Series A, 13K stars

**Decision Point:** Run benchmarks in Week 1-2. If proven 10-100x faster, pursue this path.

---

### Path 2: Feature-First Strategy ğŸ¯

**Positioning:** "Embedded PostgreSQL + Vectors for AI/Edge Applications"

**System Design:**
```
Core Components:
â”œâ”€â”€ Embedded Database (redb) - Zero-config, single binary
â”œâ”€â”€ PostgreSQL Wire Protocol - Full compatibility
â”œâ”€â”€ pgvector Extension - Vector similarity search
â”œâ”€â”€ DataFusion Query Engine - Fast SQL
â””â”€â”€ Sync Service (Optional) - Multi-device, cloud backup

Differentiators:
â”œâ”€â”€ ONLY embedded PostgreSQL with vectors
â”œâ”€â”€ Pure Rust (safe, fast, cross-platform)
â”œâ”€â”€ Works offline (local-first)
â””â”€â”€ Optional cloud sync (not required)
```

**Business Model:**
- **Free:** Embedded database (open source)
- **Starter:** $29/month - Cloud sync (1 device, 10GB)
- **Pro:** $99/month - Multi-device sync (unlimited devices, 100GB)
- **Enterprise:** $499-5K/month - Team features, compliance, support

**Target Market:**
- AI/RAG application developers (LangChain, LlamaIndex users)
- Edge AI deployments (robotics, IoT, offline ML)
- Local-first applications (privacy-focused, offline-capable)
- Embedded analytics (desktop apps, mobile)

**Revenue Potential:**
- Year 1: $30K-100K MRR ($360K-1.2M ARR)
- Year 3: $200K-500K MRR ($2.4M-6M ARR)

**Requirements:**
- âš ï¸ Add pgvector integration (4-6 weeks)
- âš ï¸ Build sync service (6-8 weeks)
- âš ï¸ Create examples (RAG app, edge AI) (2-3 weeks)
- âš ï¸ Launch on Hacker News, Product Hunt

**Funding Strategy:**
- Bootstrap-to-revenue first: $30K-100K MRR
- Then raise Angel/Seed: $500K-1M after proving market
- Series A: $3-10M after $1M+ ARR

**Risk Level:** Medium technical risk, medium reward potential

**Success Examples:**
- Supabase: Embedded Postgres â†’ $395M raised, $31M revenue (2024)
- Neon: Serverless Postgres â†’ $238M raised
- Turso: Edge SQLite â†’ $7.5M seed

**Decision Point:** If benchmarks show <5x speedup, or market validation comes faster than tech validation, pursue this path.

---

### Path 3: Hybrid Strategy (Recommended) ğŸš€

**Positioning:** "Fastest embedded database for time-series and AI workloads"

**System Design:**
```
Phase 1: Core (Months 1-2)
â”œâ”€â”€ Validate learned indexes at scale (10M-1B rows)
â”œâ”€â”€ Add pgvector integration
â”œâ”€â”€ Package as embedded library
â””â”€â”€ Run comparative benchmarks

Phase 2: Market (Months 3-6)
â”œâ”€â”€ Launch open source on GitHub
â”œâ”€â”€ Build examples and tutorials
â”œâ”€â”€ Get first 100-500 users
â””â”€â”€ Identify paying customer segment

Phase 3: Revenue or Raise (Months 6-12)
â”œâ”€â”€ IF algorithms proven: Raise $1-3M based on tech moat
â”œâ”€â”€ IF market proven: Bootstrap to $50K-100K MRR
â””â”€â”€ Build team and scale

Hybrid Architecture:
â”œâ”€â”€ Learned Index Layer (for time-series, sequential data)
â”œâ”€â”€ Standard B-tree Layer (for random access, updates)
â”œâ”€â”€ Auto-detection (pick best index for workload)
â””â”€â”€ User can force either mode
```

**Business Model:**
- Start with **Open Core** (free core + paid cloud/enterprise)
- Add **Managed Service** (after proving tech works)
- Grow to **COSS** (commercial open source, 7-14x better exits)

**Two Pitches Prepared:**

**Tech Pitch (if algorithms win):**
> "We're 50x faster than SQLite on time-series workloads using learned indexes.
> PostgreSQL-compatible, works offline. $1.45B time-series + $4B vector market."

**Market Pitch (if market wins first):**
> "Embedded PostgreSQL + vectors for AI apps. Only solution that works offline.
> 1,200 GitHub stars, 300 active users, $5K MRR growing 40% MoM."

**Target Market:**
- Primary: AI/RAG developers (large, fast-growing)
- Secondary: IoT/time-series (learned index advantage)
- Tertiary: Edge computing (embedded + sync)

**Revenue Potential:**
- Year 1: $100K-300K ARR (validated market OR algorithm)
- Year 3: $5M-15M ARR (both validated)

**Requirements:**
- Week 1-2: Run benchmarks (TPC-H, vector search, time-series)
- Week 3-6: Add pgvector + examples
- Week 7-8: Launch + get first users
- Week 9-12: Decide: raise funding OR bootstrap

**Funding Strategy:**
- Flexible: Can raise early (if tech wins) or late (if market wins)
- YC/Seed: $500K-3M (either tech moat OR traction story)
- Series A: $10-30M (both tech + market proven)

**Risk Level:** Medium (de-risked by parallel validation)

**Why This Works:**
1. âœ… De-risks both technical and market uncertainty
2. âœ… Gives you TWO pitches for investors
3. âœ… Follows successful patterns (DuckDB, Supabase)
4. âœ… Maximizes funding chances (tech OR market, ideally both)

---

## Decision Framework

### Week 1-2: Validation Phase

Run these benchmarks **immediately**:

```bash
# 1. Time-series benchmark
cargo run --release --bin bench_timeseries -- --rows 10000000

# 2. Vector search benchmark
cargo run --release --bin bench_vectors -- --vectors 1000000 --dim 128

# 3. TPC-H analytical benchmark
cargo run --release --bin bench_tpch
```

**Compare against:**
- PostgreSQL (baseline)
- SQLite (embedded baseline)
- DuckDB (analytics baseline)
- pgvector (vector baseline)

### Decision Matrix

| Benchmark Result | Strategy | Positioning | Funding Path |
|-----------------|----------|-------------|--------------|
| **10-100x faster** on time-series | Path 1: Algorithm-First | "Fastest embedded DB for time-series + AI" | Raise $1-3M seed immediately |
| **10-100x faster** on vector search | Path 1: Algorithm-First | "Fastest vector DB (PostgreSQL-compatible)" | Raise $1-3M seed immediately |
| **2-5x faster** on time-series | Path 3: Hybrid | "Fast embedded PostgreSQL + vectors" | Bootstrap first, raise after $50K MRR |
| **<2x faster** on all benchmarks | Path 2: Feature-First | "Embedded PostgreSQL for AI/Edge" | Bootstrap to $30K-100K MRR, then raise |

### Week 3-4: Execute

**If Path 1 (Algorithm-First):**
1. Write technical blog post: "Learned Indexes: 100x Faster Time-Series"
2. Launch on Hacker News: "Show HN: Fastest embedded database"
3. Apply to YC with "better algorithms" story
4. Target: 2K-5K GitHub stars from technical community

**If Path 2 (Feature-First):**
1. Add pgvector integration (4 weeks)
2. Build AI/RAG tutorials
3. Launch on Product Hunt, AI/ML communities
4. Target: First paying customers within 6 weeks

**If Path 3 (Hybrid):**
1. Do BOTH in parallel
2. See which gains traction faster
3. Double down on winner
4. Have backup pitch ready

---

## Technical Architecture Comparison

### Algorithm-First Architecture

```
Performance-Optimized Stack:

Storage Layer:
â”œâ”€â”€ Learned Index (RMI) - O(1) lookups for sequential keys
â”œâ”€â”€ B-tree Index (fallback) - For updates, random access
â””â”€â”€ Arrow/Parquet - Columnar storage for analytics

Query Layer:
â”œâ”€â”€ DataFusion - Optimized SQL engine
â”œâ”€â”€ Filter Pushdown - Reduce data scanned
â”œâ”€â”€ LIMIT Pushdown - Early termination
â””â”€â”€ Streaming Execution - Low memory

Protocol Layer:
â”œâ”€â”€ PostgreSQL Wire Protocol - psql, drivers
â””â”€â”€ REST API - Modern HTTP/JSON

Key Innovations:
â”œâ”€â”€ Hybrid indexing (learned + B-tree)
â”œâ”€â”€ Workload detection (auto-pick best index)
â””â”€â”€ SIMD optimization (vectorized learned index)
```

**Pros:**
- âœ… Technical moat (hard to replicate)
- âœ… Clear differentiation (10-100x faster)
- âœ… Large market (time-series $1.45B + vectors $4B)

**Cons:**
- âŒ Requires proving algorithm advantage
- âŒ Higher technical complexity
- âŒ Longer time to market (3-4 months)

### Feature-First Architecture

```
Simplicity-Optimized Stack:

Storage Layer:
â”œâ”€â”€ redb - Embedded ACID storage (proven)
â””â”€â”€ Standard B-tree indexes

Query Layer:
â”œâ”€â”€ DataFusion - SQL engine (no custom optimization)
â””â”€â”€ pgvector - Vector similarity search

Protocol Layer:
â”œâ”€â”€ PostgreSQL Wire Protocol
â””â”€â”€ Optional: Sync service for multi-device

Extensions:
â”œâ”€â”€ pgvector (vectors)
â””â”€â”€ Future: pg_cron, pg_partman, etc.

Key Innovations:
â”œâ”€â”€ First embedded PostgreSQL with vectors
â”œâ”€â”€ Pure Rust (safe, fast, cross-platform)
â””â”€â”€ Optional cloud sync (not required)
```

**Pros:**
- âœ… Faster time to market (6-8 weeks)
- âœ… Proven technology (less risk)
- âœ… Clear market need (AI/RAG apps)

**Cons:**
- âŒ Less technical differentiation
- âŒ Competitors can copy features
- âŒ Smaller initial market (AI developers vs all databases)

### Hybrid Architecture (Recommended)

```
Adaptive Stack:

Storage Layer:
â”œâ”€â”€ Learned Index (for time-series, append-only)
â”œâ”€â”€ B-tree Index (for random access, OLTP)
â”œâ”€â”€ Auto-detection (analyze workload, pick best index)
â””â”€â”€ User override (force learned or B-tree)

Query Layer:
â”œâ”€â”€ DataFusion with custom execution plans
â”œâ”€â”€ Workload-aware optimization
â””â”€â”€ pgvector integration

Protocol Layer:
â”œâ”€â”€ PostgreSQL Wire Protocol (full compatibility)
â””â”€â”€ Optional sync service

Deployment Modes:
â”œâ”€â”€ Embedded (single binary, local-first)
â”œâ”€â”€ Standalone (server mode)
â””â”€â”€ Managed (cloud service)
```

**Pros:**
- âœ… Best of both worlds (tech + market)
- âœ… Flexible positioning based on validation
- âœ… Multiple revenue streams

**Cons:**
- âŒ More complex to build initially
- âŒ Requires validating both tech and market

---

## Recommendation: Path 3 (Hybrid)

### Why Hybrid is Best

1. **De-risks uncertainty:** You don't know yet if algorithms or market will win. Validate both in parallel.

2. **Flexible positioning:** After 6-8 weeks, you'll know whether to lead with:
   - "100x faster" (if benchmarks prove it)
   - "Embedded PostgreSQL + vectors" (if market proves it)
   - "Fast embedded PostgreSQL for time-series + AI" (if both prove it)

3. **Maximizes funding chances:** VCs want either:
   - 10x better tech (technical moat)
   - OR fast-growing users (market validation)
   - You'll have at least one, hopefully both

4. **Follows success patterns:**
   - DuckDB: Started with algorithms, added market fit
   - Supabase: Started with market, added tech differentiation
   - Both are highly successful

### Implementation Plan (12 Weeks)

**Weeks 1-2: Brutal Validation**
```bash
# Run benchmarks (20 hours)
- TPC-H vs PostgreSQL, DuckDB
- Vector search vs pgvector, Pinecone
- Time-series vs SQLite, QuestDB

# Decision point:
- IF 10-100x faster: Lead with algorithms
- IF <5x faster: Lead with features
- IF 10-50x on time-series only: Hybrid positioning
```

**Weeks 3-6: Build Core**
```bash
# Add missing features (80 hours)
- pgvector integration (30h)
- Sync service MVP (30h)
- Examples (RAG app, time-series) (20h)
```

**Weeks 7-8: Launch**
```bash
# Go to market (40 hours)
- Technical blog post (10h)
- Documentation + quickstart (10h)
- Launch on HN, Product Hunt (10h)
- Customer discovery interviews (10h)
```

**Weeks 9-12: Scale or Raise**
```bash
# Path A: Raise funding
- YC application (tech or market story)
- Angel investor outreach
- Demo Day preparation

# Path B: Bootstrap
- Get first 10 paying customers
- $5K-10K MRR
- Iterate based on feedback
```

### Success Metrics (Week 12)

**Minimum Viable Traction (for YC):**
- âœ… 1,000-5,000 GitHub stars
- âœ… 100-500 active users
- âœ… $2K-10K MRR (optional but strong)
- âœ… 10-20 customer interviews (market validation)
- âœ… Reproducible benchmarks (tech validation)

**Funding Readiness:**
- IF tech proven: "We're 50x faster than SQLite on time-series" â†’ Raise $1-3M
- IF market proven: "300 active users, $5K MRR growing 40% MoM" â†’ Raise $500K-1M
- IF both: "50x faster + 300 users + $5K MRR" â†’ Raise $2-5M

---

## Bottom Line

**Three viable paths exist. Hybrid (Path 3) is recommended because:**

1. âœ… You don't know yet if algorithms or market will win
2. âœ… Validating both in parallel costs only 6-8 weeks
3. âœ… You'll have TWO pitches for investors (tech + market)
4. âœ… Either way, you have a fundable company

**Next Action (This Week):**

```bash
# 1. Run benchmarks (Day 1-2)
cargo run --release --bin bench_all

# 2. Analyze results (Day 3)
# Are we 10-100x faster on ANY workload?

# 3. Decide positioning (Day 4)
# "Fastest DB for X" OR "Embedded PostgreSQL + Vectors" OR "Both"

# 4. Start building (Day 5-7)
# Add pgvector, start sync service, write examples
```

**Within 12 weeks, you'll either:**
- Have $5K-10K MRR and growing (bootstrap path)
- OR be raising $500K-3M (VC path)
- OR have clear signal to pivot

All three outcomes are successful. The key is **validate fast, decide fast, execute fast**.
